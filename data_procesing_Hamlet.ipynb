{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb514b7",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "#### Task\n",
    "Determine 10 most frequent words in \"Hamlet\".\n",
    "\n",
    "#### Assumptions:\n",
    "Do not distinguish between lower and upper case words.\n",
    "Treat plurals as separate words ('ghost' and 'ghosts' are different words).\n",
    "Include \"left-overs\" after split, such as 'd' in \"we'd\".\n",
    "Include character names \n",
    "\n",
    "Text gotten from Project Gutenberg: http://www.gutenberg.org/cache/epub/2265/pg2265.txt. \n",
    "Plain text format. Remove the Gutenberg preface and legal note.\n",
    "\n",
    "Step 1:\n",
    "Read a bit of the file and print it so we can easily see what is that we need to do with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "230ec3c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Tragedie of Hamlet\n",
      "\n",
      "\n",
      "\n",
      "Actus Primus. Scoena Prima.\n",
      "\n",
      "\n",
      "\n",
      "Enter Barnardo and Francisco two Centinels.\n",
      "\n",
      "\n",
      "\n",
      "  Barnardo. Who's there?\n",
      "\n",
      "  Fran. Nay answer me: Stand & vnfold\n",
      "\n",
      "your selfe\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('C:\\\\Users\\\\inese\\\\OneDrive\\\\Escritorio\\\\OneDrive\\\\Hamlet.txt','r') as inp:\n",
    "    for i in range(10):\n",
    "        line = inp.readline()\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee1397",
   "metadata": {},
   "source": [
    "Step 2: Roughcleaning up. Remove all \"hidden\" characters (trailing end-of-line symbols, leading tabs, etc.)\n",
    "Split each line into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60bf98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\inese\\\\OneDrive\\\\Escritorio\\\\OneDrive\\\\Hamlet.txt','r') as inp:\n",
    "    for line in inp:\n",
    "        cleaned_line = line.strip()  # Remove trailing line breaks\n",
    "        words = cleaned_line.split() # Split the line and add to list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601a21d",
   "metadata": {},
   "source": [
    "Step 3: We need to clean up each word. \n",
    "\n",
    "Algorithm:\n",
    "\n",
    "Loop over all words in a line. Call function clean_word() on each word.\n",
    "For a word define an empty string called new_word.\n",
    "Loop over all characters of the word.\n",
    "a) If the character is a letter (use string.ascii_letters) add it to the new_word\n",
    "b) Else add white space \" \" to new_word\n",
    "Split new_word at white spaces.\n",
    "Return a list with all split words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f6559ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string as s\n",
    "\n",
    "def clean_word(word):\n",
    "    new_word = \"\"\n",
    "    for char in word:\n",
    "        if char in s.ascii_letters:\n",
    "            new_word += char\n",
    "        else:\n",
    "            new_word += ' '\n",
    "    return new_word.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc65f6",
   "metadata": {},
   "source": [
    "In main code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3e35973",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\inese\\\\OneDrive\\\\Escritorio\\\\OneDrive\\\\Hamlet.txt','r') as inp:\n",
    "    for line in inp:\n",
    "        cleaned_line = line.strip()  # Remove trailing line breaks\n",
    "        words = cleaned_line.split() # Split it at white spaces\n",
    "        cleaned_words = []\n",
    "        for i in range(len(words)):\n",
    "            word = words[i].lower()\n",
    "            cleaned_words.extend(clean_word(word))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e164c",
   "metadata": {},
   "source": [
    "Step 4: Collect all \"cleaned up\" words and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc72514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_words = []\n",
    "with open('C:\\\\Users\\\\inese\\\\OneDrive\\\\Escritorio\\\\OneDrive\\\\Hamlet.txt','r') as inp:\n",
    "    for line in inp:\n",
    "        cleaned_line = line.strip()  # Remove trailing line breaks\n",
    "        words = cleaned_line.split()\n",
    "        cleaned_words = []\n",
    "        for i in range(len(words)):\n",
    "            word = words[i].lower()\n",
    "            cleaned_words.extend(clean_word(word))\n",
    "        hamlet_words.extend(cleaned_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88727dc",
   "metadata": {},
   "source": [
    "For convenience, we'll place all cleaning up of the text into a function (file_to_words())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dda32e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_words(filename):\n",
    "    all_words = []\n",
    "    with open(filename,'r') as inp:\n",
    "        for line in inp:\n",
    "            cleaned_line = line.strip()  # Remove trailing line breaks\n",
    "            words = cleaned_line.split() # Split the line into \"words\"\n",
    "            # clean things up            \n",
    "            cleaned_words = []\n",
    "            for i in range(len(words)):\n",
    "                word = words[i].lower()\n",
    "                cleaned_words.extend(clean_word(word))\n",
    "            all_words.extend(cleaned_words)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ceee1",
   "metadata": {},
   "source": [
    "Step 5: We keep track of the number of occurrences of a word using a dictionary.\n",
    "\n",
    "Key < == > word\n",
    "Value < == > number of occurrences of the word.\n",
    "\n",
    "Note: We will assume that all keys are lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a3907bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = {}\n",
    "\n",
    "hamlet = file_to_words('C:\\\\Users\\\\inese\\\\OneDrive\\\\Escritorio\\\\OneDrive\\\\Hamlet.txt')\n",
    "\n",
    "for word in hamlet:\n",
    "    if not word in word_count:\n",
    "        word_count[word] = 1\n",
    "    else:\n",
    "        word_count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d34436",
   "metadata": {},
   "source": [
    "Step 6: Put all together \n",
    "\n",
    "Convert the dictionary into the list of pairs.\n",
    "Sort this list by the number of occurrences (reversed sort).\n",
    "Get first 10 elements of the sorted list.\n",
    "Make a pretty looking output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7a36be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most frequent words are:\n",
      "--------------------------------------------------------------------------------\n",
      "Word  THE   appears   993 times, which is 3.28% of the text : ***\n",
      "Word  AND   appears   863 times, which is 2.85% of the text : ***\n",
      "Word   TO   appears   685 times, which is 2.26% of the text : **\n",
      "Word   OF   appears   610 times, which is 2.02% of the text : **\n",
      "Word   I    appears   574 times, which is 1.90% of the text : **\n",
      "Word  YOU   appears   527 times, which is 1.74% of the text : **\n",
      "Word   A    appears   511 times, which is 1.69% of the text : **\n",
      "Word   MY   appears   502 times, which is 1.66% of the text : **\n",
      "Word   IT   appears   419 times, which is 1.38% of the text : *\n",
      "Word   IN   appears   400 times, which is 1.32% of the text : *\n",
      "Word  THAT  appears   377 times, which is 1.25% of the text : *\n"
     ]
    }
   ],
   "source": [
    "import string as s\n",
    "from operator import itemgetter\n",
    "\n",
    "def clean_word(word):\n",
    "    new_word = \"\"\n",
    "    for char in word:\n",
    "        if char in s.ascii_letters:\n",
    "            new_word += char\n",
    "        else:\n",
    "            new_word += ' '\n",
    "    return new_word.split()\n",
    "\n",
    "# Function that produces 'clean' words\n",
    "def file_to_words(filename):\n",
    "    all_words = []\n",
    "    with open(filename,'r') as inp:\n",
    "        for line in inp:\n",
    "            cleaned_line = line.strip()  # Remove trailing line breaks\n",
    "            words = cleaned_line.split() # Split the line into \"words\"\n",
    "            # clean things up            \n",
    "            cleaned_words = []\n",
    "            for i in range(len(words)):\n",
    "                word = words[i].lower()\n",
    "                cleaned_words.extend(clean_word(word))\n",
    "            all_words.extend(cleaned_words)\n",
    "    return all_words\n",
    "\n",
    "# Dictionary that will contatain word counts\n",
    "word_count = {}\n",
    "\n",
    "# Call function file_to_words() with the text of Hamlet as its argument\n",
    "hamlet = file_to_words('C:\\\\Users\\\\inese\\\\OneDrive\\\\Escritorio\\\\OneDrive\\\\Hamlet.txt')\n",
    "\n",
    "# Do word counting \n",
    "for word in hamlet:\n",
    "    if not word in word_count:\n",
    "        word_count[word] = 1\n",
    "    else:\n",
    "        word_count[word] += 1\n",
    "        \n",
    "# find most frequent word\n",
    "word_count_list = list(word_count.items())  # Transform dictionary into a list of pairs\n",
    "word_count_list.sort(key=itemgetter(1),reverse=True)   # Sort by number of apperences, in reversed order\n",
    "\n",
    "# Produce pretty output \n",
    "print('10 most frequent words are:')\n",
    "print('-'*80)\n",
    "for i in range(11):\n",
    "    word = word_count_list[i][0]\n",
    "    appears_times = word_count_list[i][1]\n",
    "    percent = 100*appears_times/len(hamlet)\n",
    "    int_perc = int(round(percent))\n",
    "    print('Word {:^6s} appears {:5d} times, which is {:.2f}% of the text'.format(word.upper(),appears_times,percent), end=' : ' )\n",
    "    stars = '*'*int_perc\n",
    "    print(stars)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
