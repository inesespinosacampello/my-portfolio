{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb514b7",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "#### Task\n",
    "Determine 10 most frequent words in \"Hamlet\".\n",
    "\n",
    "#### Assumptions:\n",
    "Include \"stage comments\" in the analysis (e.g. [Enter Horatio and Marcellus.]).\n",
    "Do not distinguish between lower and upper case words.\n",
    "Treat plurals as separate words ('ghost' and 'ghosts' are different words).\n",
    "Include \"left-overs\" after split, such as 'd' in \"we'd\".\n",
    "Include character names (e.g., \"Bar. Say, what is Horatio there?\").\n",
    "Before we start...\n",
    "\n",
    "Text gotten from Project Gutenberg: http://www.gutenberg.org/cache/epub/2265/pg2265.txt. \n",
    "Plain text format. Remove the Gutenberg preface and legal note.\n",
    "\n",
    "Before starting need to make sure that the file is cleaned (removed preface) and placed in the appropriate folder (same as the code).\n",
    "\n",
    "Step 1:\n",
    "Read in the entire file and print it. This way we can easily see what is that we need to do with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ec3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hamlet.txt','r') as inp:\n",
    "    hamlet = inp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hamlet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afbbef",
   "metadata": {},
   "source": [
    "Step 2: Read line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hamlet_clean.txt','r') as inp:\n",
    "    for line in inp:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee1397",
   "metadata": {},
   "source": [
    "Step 3:roughcleaning up.\n",
    "\n",
    "We will:\n",
    "\n",
    "Remove all \"hidden\" characters (trailing end-of-line symbols, leading tabs, etc.)\n",
    "Split each line into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hamlet_clean.txt','r') as inp:\n",
    "    for line in inp:\n",
    "        cleaned_line = line.strip()  # Remove trailing line breaks\n",
    "        words = cleaned_line.split() # Split the line\n",
    "        print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601a21d",
   "metadata": {},
   "source": [
    "Step 4: We need to clean up each word. \n",
    "\n",
    "Algorithm:\n",
    "\n",
    "Loop over all words in a line. Call function clean_word() on each word.\n",
    "For a word define an empty string called new_word.\n",
    "Loop over all characters of the word.\n",
    "a) If the character is a letter (use string.ascii_letters) add it to the new_word\n",
    "b) Else add white space \" \" to new_word\n",
    "Split new_word at white spaces.\n",
    "Return a list with all split words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6559ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string as s\n",
    "\n",
    "def clean_word(word):\n",
    "    new_word = \"\"\n",
    "    for char in word:\n",
    "        if char in s.ascii_letters:\n",
    "            new_word += char\n",
    "        else:\n",
    "            new_word += ' '\n",
    "    return new_word.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc65f6",
   "metadata": {},
   "source": [
    "In main code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e35973",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hamlet_clean.txt','r') as inp:\n",
    "    for line in inp:\n",
    "        cleaned_line = line.strip()  # Remove trailing line breaks\n",
    "        words = cleaned_line.split() # Split it at white spaces\n",
    "        cleaned_words = []\n",
    "        for i in range(len(words)):\n",
    "            word = words[i].lower()\n",
    "            cleaned_words.extend(clean_word(word))\n",
    "        print(cleaned_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e164c",
   "metadata": {},
   "source": [
    "Step 5: Collect all \"cleaned up\" words and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_words = []\n",
    "with open('hamlet_clean.txt','r') as inp:\n",
    "    for line in inp:\n",
    "        cleaned_line = line.strip()  # Remove trailing line breaks\n",
    "        words = cleaned_line.split()\n",
    "        cleaned_words = []\n",
    "        for i in range(len(words)):\n",
    "            word = words[i].lower()\n",
    "            cleaned_words.extend(clean_word(word))\n",
    "        hamlet_words.extend(cleaned_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3ceee1",
   "metadata": {},
   "source": [
    "Step 6: We keep track of the number of occurrences of a word using a dictionary.\n",
    "\n",
    "Key < == > word\n",
    "Value < == > number of occurrences of the word.\n",
    "\n",
    "Note: We will assume that all keys are lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3907bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = {}\n",
    "\n",
    "hamlet = file_to_words('hamlet_clean.txt')\n",
    "\n",
    "for word in hamlet:\n",
    "    if not word in word_count:\n",
    "        word_count[word] = 1\n",
    "    else:\n",
    "        word_count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ee37b",
   "metadata": {},
   "source": [
    "We'll place all cleaning up of the text into a function (file_to_words())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa47fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_words(filename):\n",
    "    all_words = []\n",
    "    with open(filename,'r') as inp:\n",
    "        for line in inp:\n",
    "            cleaned_line = line.strip()  # Remove trailing line breaks\n",
    "            words = cleaned_line.split() # Split the line into \"words\"\n",
    "            # clean things up            \n",
    "            cleaned_words = []\n",
    "            for i in range(len(words)):\n",
    "                word = words[i].lower()\n",
    "                cleaned_words.extend(clean_word(word))\n",
    "            all_words.extend(cleaned_words)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d34436",
   "metadata": {},
   "source": [
    "Step 7: Put all together \n",
    "\n",
    "Convert the dictionary into the list of pairs.\n",
    "Sort this list by the number of occurrences (reversed sort).\n",
    "Get first 10 elements of the sorted list.\n",
    "Make a pretty looking output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a36be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string as s\n",
    "from operator import itemgetter\n",
    "\n",
    "def clean_word(word):\n",
    "    new_word = \"\"\n",
    "    for char in word:\n",
    "        if char in s.ascii_letters:\n",
    "            new_word += char\n",
    "        else:\n",
    "            new_word += ' '\n",
    "    return new_word.split()\n",
    "\n",
    "# Function that produces 'clean' words\n",
    "def file_to_words(filename):\n",
    "    all_words = []\n",
    "    with open(filename,'r') as inp:\n",
    "        for line in inp:\n",
    "            cleaned_line = line.strip()  # Remove trailing line breaks\n",
    "            words = cleaned_line.split() # Split the line into \"words\"\n",
    "            # clean things up            \n",
    "            cleaned_words = []\n",
    "            for i in range(len(words)):\n",
    "                word = words[i].lower()\n",
    "                cleaned_words.extend(clean_word(word))\n",
    "            all_words.extend(cleaned_words)\n",
    "    return all_words\n",
    "\n",
    "# Dictionary that will contatain word counts\n",
    "word_count = {}\n",
    "\n",
    "# Call function file_to_words() with the text of Hamlet as its argument\n",
    "hamlet = file_to_words('hamlet_clean.txt')\n",
    "\n",
    "# Do word counting \n",
    "for word in hamlet:\n",
    "    if not word in word_count:\n",
    "        word_count[word] = 1\n",
    "    else:\n",
    "        word_count[word] += 1\n",
    "        \n",
    "# find most frequent word\n",
    "word_count_list = list(word_count.items())  # Transform dictionary into a list of pairs\n",
    "word_count_list.sort(key=itemgetter(1),reverse=True)   # Sort by number of apperences, in reversed order\n",
    "\n",
    "# Produce pretty output \n",
    "print('10 most frequent words are:')\n",
    "print('-'*80)\n",
    "for i in range(11):\n",
    "    word = word_count_list[i][0]\n",
    "    appears_times = word_count_list[i][1]\n",
    "    percent = 100*appears_times/len(hamlet)\n",
    "    int_perc = int(round(percent))\n",
    "    print('Word {:^6s} appears {:5d} times, which is {:.2f}% of the text'.format(word.upper(),appears_times,percent), end=' : ' )\n",
    "    stars = '*'*int_perc\n",
    "    print(stars)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
